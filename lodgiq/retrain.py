import logging
import os
from typing import Tuple
import numpy as np
import pandas as pd

from .config import (
    MONITOR_DIR,
    MAE_DRIFT_MULTIPLIER,
    DRIFT_WINDOW_DAYS,
    MODELS_DIR,
)
from .features import create_lag_features
from .ml_lightgbm import HAS_LGB, train_lightgbm
from .utils import ensure_dir, save_json

logger = logging.getLogger(__name__)


def check_retrain_trigger(metrics_history_path: str, drift_report: dict) -> Tuple[bool, dict]:
    reasons = {}
    trigger = False
    if drift_report.get('drift'):
        trigger = True
        reasons['drift'] = 'data_distribution_drift_detected'
    if os.path.exists(metrics_history_path):
        try:
            mh = pd.read_csv(metrics_history_path)
            mh['run_time_utc'] = pd.to_datetime(mh['run_time_utc'], utc=True, errors='coerce').dt.tz_convert(None)
            now = pd.Timestamp.now(tz='UTC').tz_convert(None)
            recent_cut = now - pd.Timedelta(days=DRIFT_WINDOW_DAYS)
            recent = mh[mh['run_time_utc'] >= recent_cut]
            hist = mh[mh['run_time_utc'] < recent_cut]
            if len(hist) >= 3 and len(recent) >= 3:
                hist_mae = hist['mae'].mean()
                recent_mae = recent['mae'].mean()
                if recent_mae > MAE_DRIFT_MULTIPLIER * hist_mae:
                    trigger = True
                    reasons['perf'] = f"recent_mae={recent_mae:.4f} > {MAE_DRIFT_MULTIPLIER}*hist_mae({hist_mae:.4f})"
        except Exception as e:
            logger.exception("Failed to compute MAE drift from history: %s", e)
    return trigger, reasons


def auto_retrain_if_triggered(df: pd.DataFrame, run_meta: dict, run_ts: str):
    logger.info("Auto-retrain invoked for run %s", run_ts)
    feats = create_lag_features(df, target_col='occ').dropna()
    holdout = 30
    if len(feats) < holdout + 50:
        logger.warning("Not enough data to auto-retrain (need more history). Aborting retrain.")
        return {'retrained': False, 'reason': 'insufficient_data'}
    X = feats.drop(columns=['y'])
    y = feats['y']
    X_train = X.iloc[:-holdout]
    y_train = y.iloc[:-holdout]
    X_val = X.iloc[-holdout:]
    y_val = y.iloc[-holdout:]
    if not HAS_LGB:
        logger.warning("LightGBM not available; cannot auto-retrain.")
        return {'retrained': False, 'reason': 'lightgbm_missing'}
    try:
        model, metrics = train_lightgbm(X_train, y_train, X_val, y_val)
        logger.info("Auto-retrain validation metrics: %s", metrics)
        baseline_rmse = run_meta.get('validation_test_rmse')
        if baseline_rmse is None or (metrics and metrics['rmse'] < baseline_rmse):
            ensure_dir(MODELS_DIR)
            model_path = os.path.join(MODELS_DIR, f"occ_lgbm_promoted_{run_ts}.txt")
            model.save_model(model_path)
            logger.info("Promoted retrained model to %s (improved RMSE %s -> %.4f)", model_path, baseline_rmse or 'nan', metrics['rmse'])
            return {'retrained': True, 'model_path': model_path, 'metrics': metrics}
        logger.info("Retrained model did not improve baseline (%.4f <= %.4f). Not promoting.", metrics['rmse'], baseline_rmse)
        return {'retrained': False, 'metrics': metrics, 'reason': 'no_improvement'}
    except Exception as e:
        logger.exception("Auto-retrain failed: %s", e)
        return {'retrained': False, 'reason': str(e)}


def generate_retrain_plan(run_ts: str):
    plan = {
        'run_ts': run_ts,
        'schedule': 'weekly',
        'triggers': {
            'data_drift_ks_pvalue': 0.01,
            'perf_mae_multiplier': MAE_DRIFT_MULTIPLIER,
        },
        'steps': [
            'ingest_data -> preprocess',
            'compute_features',
            'train_candidate_models (lightgbm)',
            'validate_on_holdout',
            'smoke_tests (basic metrics)',
            'promote_model_if_validated',
        ],
        'notes': 'Adapt this plan into Airflow/Prefect. Generated by LodgIQ pipeline.',
    }
    path = os.path.join("data", "retrain", f"retrain_plan_{run_ts}.json")
    ensure_dir(os.path.dirname(path))
    save_json(plan, path, logger)
    logger.info("Generated retrain plan: %s", path)
    return path
